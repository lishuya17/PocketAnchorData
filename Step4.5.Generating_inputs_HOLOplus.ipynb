{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, pickle, sys, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from pymol import cmd\n",
    "from sklearn.metrics import pairwise_distances, pairwise_distances_argmin_min\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from scipy.cluster.hierarchy import fcluster, linkage, single\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Define dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = 6\n",
    "outdir = './PocketDetectionData_HOLOplus_da{}/'.format(da)\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491, 4)\n"
     ]
    }
   ],
   "source": [
    "table = pd.read_csv('/data/lishuya/lab/PocketAnchor/Revise1_new_data/Clean_protein_HOLO4k_table.tsv',\n",
    "                        sep='\\t')\n",
    "holo_ligand_table = pd.read_csv(\"lists/holo4k_pdbid_ligandname.csv\")\n",
    "ligand_dict = {}\n",
    "for i in holo_ligand_table.index:\n",
    "    list_ligand = eval(holo_ligand_table.loc[i, 'ligand_name'])\n",
    "    ligand_dict[holo_ligand_table.loc[i, 'pdbid']] = \",\".join(list_ligand)\n",
    "ligand_list =  [ligand_dict[pdbid] for pdbid in table['original_sample']]\n",
    "table['ligand'] = ligand_list\n",
    "print(table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_new_name = {\n",
    "#     '1fpx':'6cig', \n",
    "#     '1m98':'5ui2', \n",
    "#     '1pmq':'4z9l'\n",
    "# }\n",
    "def update_pdbid_chains(pdbid_chains):\n",
    "    return pdbid_chains\n",
    "#     pdbid, chains = pdbid_chains.split(\"_\")\n",
    "#     if pdbid not in dict_new_name:\n",
    "#         return pdbid_chains\n",
    "#     newid = dict_new_name[pdbid]\n",
    "#     return \"_\".join([newid, chains])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_chains = {}\n",
    "for i in table.index:\n",
    "    pdbid, chains = table.loc[i, ['pdbid', 'chains']]\n",
    "    dict_chains[pdbid] = [chains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbid</th>\n",
       "      <th>chains</th>\n",
       "      <th>original_sample</th>\n",
       "      <th>ligand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1bkd</td>\n",
       "      <td>R</td>\n",
       "      <td>18gs</td>\n",
       "      <td>gdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11as</td>\n",
       "      <td>AB</td>\n",
       "      <td>18gs</td>\n",
       "      <td>gdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1eog</td>\n",
       "      <td>AB</td>\n",
       "      <td>18gs</td>\n",
       "      <td>gdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1p7s</td>\n",
       "      <td>A</td>\n",
       "      <td>18gs</td>\n",
       "      <td>gdn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6wsk</td>\n",
       "      <td>A</td>\n",
       "      <td>18gs</td>\n",
       "      <td>gdn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdbid chains original_sample ligand\n",
       "0  1bkd      R            18gs    gdn\n",
       "1  11as     AB            18gs    gdn\n",
       "2  1eog     AB            18gs    gdn\n",
       "3  1p7s      A            18gs    gdn\n",
       "4  6wsk      A            18gs    gdn"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_anchor(list_samples):\n",
    "    list_anchor = []\n",
    "    for pdbid_chains in list_samples:\n",
    "        pdbid_chains = update_pdbid_chains(pdbid_chains)\n",
    "        anchor = np.load('AnchorOutput/{}_da_{}/anchors.npy'.format(pdbid_chains, da))[0]\n",
    "        list_anchor.append(anchor)\n",
    "    return np.concatenate(list_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchor_dict 491\n"
     ]
    }
   ],
   "source": [
    "anchor_dict = {}\n",
    "for i in table.index:\n",
    "    print(len(anchor_dict), \"\\r\", end=\"\")\n",
    "    pdbid = table.loc[i, 'pdbid']\n",
    "    try:\n",
    "        list_chains = [pdbid + \"_\" + chain for chain in table.loc[i, 'chains'].split(\",\")]\n",
    "        anchor_dict[pdbid] = load_anchor(list_chains)\n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "        pass\n",
    "\n",
    "print(\"anchor_dict\", len(anchor_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir+'anchor_dict_thre'+str(da), 'wb') as f:\n",
    "    pickle.dump(anchor_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_atom_dict(list_filenames):\n",
    "    list_fa = []\n",
    "    list_coord = []\n",
    "    list_nei = []\n",
    "    count = 0\n",
    "    for pdbid_chains in list_filenames:\n",
    "        pdbid_chains = update_pdbid_chains(pdbid_chains)\n",
    "        fa, coord, nei = pickle.load(open('AnchorOutput/{}_da_{}/atom_feature.pk'\\\n",
    "                                          .format(pdbid_chains, da), 'rb'))[0]\n",
    "        list_fa.append(fa)\n",
    "        list_coord.append(coord)\n",
    "        list_nei.extend([[jtem + count for jtem in item] for item in nei])\n",
    "        count += len(fa)\n",
    "    list_fa = np.concatenate(list_fa)\n",
    "    list_coord = np.concatenate(list_coord)\n",
    "    return (list_fa, list_coord, list_nei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom_dict = {}\n",
    "\n",
    "for i in table.index:\n",
    "    print(len(atom_dict), \"\\r\", end=\"\")\n",
    "    pdbid = table.loc[i, 'pdbid']\n",
    "    try:\n",
    "        list_chains = [pdbid + \"_\" + chain for chain in table.loc[i, 'chains'].split(\",\")]\n",
    "        atom_dict[pdbid] = load_atom_dict(list_chains)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "len(atom_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir+\"atom_feature_coord_nei_dict_thre\"+str(da), \"wb\") as f:\n",
    "    pickle.dump(atom_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_masif_coords(list_filenames):\n",
    "    list_prt_coord = []\n",
    "    for pdbid_chains in list_filenames:\n",
    "        pdbid_chains = update_pdbid_chains(pdbid_chains)\n",
    "        masif_coords = np.vstack([\n",
    "            np.load('MasifOutput/04a-precomputation_12A/precomputation/{}/p1_X.npy'.format(pdbid_chains)),\n",
    "            np.load('MasifOutput/04a-precomputation_12A/precomputation/{}/p1_Y.npy'.format(pdbid_chains)),\n",
    "            np.load('MasifOutput/04a-precomputation_12A/precomputation/{}/p1_Z.npy'.format(pdbid_chains)),\n",
    "        ]).T\n",
    "        list_prt_coord.append(masif_coords)\n",
    "    return np.concatenate(list_prt_coord)\n",
    "\n",
    "\n",
    "def load_masif_feature_neighbor(list_filenames):\n",
    "    list_feat = []\n",
    "    list_nei = []\n",
    "    count = 0\n",
    "    for pdbid_chains in list_filenames:\n",
    "        pdbid_chains = update_pdbid_chains(pdbid_chains)\n",
    "        feat = np.load('AnchorOutput/{}_da_{}/masif_feature.npy'.format(pdbid_chains, da))\n",
    "        nei = np.load('AnchorOutput/{}_da_{}/masif_neighbor.npy'.format(pdbid_chains, da))\n",
    "        if np.isnan(feat).sum() != 0:\n",
    "            feat[np.where(np.isnan(feat))] = 0\n",
    "        list_feat.append(feat)\n",
    "        list_nei.append(nei + count)\n",
    "        count += len(feat)\n",
    "    return np.concatenate(list_feat), np.concatenate(list_nei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'AnchorOutput/1ksv_A_da_6/masif_feature.npy'\n",
      "489 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masif_feature_coord_nei_dict = {}\n",
    "\n",
    "for i in table.index:\n",
    "    print(len(masif_feature_coord_nei_dict), \"\\r\", end=\"\")\n",
    "    pdbid = table.loc[i, 'pdbid']\n",
    "    try:    \n",
    "        list_chains = [pdbid + \"_\" + chain for chain in table.loc[i, 'chains'].split(\",\")]    \n",
    "        masif_feature, masif_neighbor = load_masif_feature_neighbor(list_chains)\n",
    "        masif_coords = load_masif_coords(list_chains)\n",
    "        assert masif_feature.shape[0] == masif_coords.shape[0], \"{} {} {}\".format(pdbid, masif_feature.shape[0], masif_coords.shape[0])\n",
    "\n",
    "        masif_feature_coord_nei_dict[pdbid] = (masif_feature, masif_coords, masif_neighbor)\n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "        pass\n",
    "len(masif_feature_coord_nei_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir+'masif_feature_coord_nei_dict', 'wb') as f:\n",
    "    pickle.dump(masif_feature_coord_nei_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 490 490 \n"
     ]
    }
   ],
   "source": [
    "am_dict = {}\n",
    "aa_dict = {}\n",
    "at_dict = {}\n",
    "for i in table.index:\n",
    "    print(len(am_dict), len(aa_dict), len(at_dict), \"\\r\", end=\"\")\n",
    "    pdbid = table.loc[i, 'pdbid']\n",
    "    try:  \n",
    "        anchor_coords = anchor_dict[pdbid]\n",
    "        masif_coords = masif_feature_coord_nei_dict[pdbid][1]\n",
    "        atom_coords = atom_dict[pdbid][1]\n",
    "        \n",
    "        # aa\n",
    "        aa_dist = pairwise_distances(anchor_coords, anchor_coords)\n",
    "        sele = np.where(aa_dist<=6)\n",
    "        i = torch.LongTensor(np.vstack(sele))\n",
    "        v = torch.FloatTensor(aa_dist[sele])\n",
    "        aa_sparse = torch.sparse.FloatTensor(i, v, torch.Size([aa_dist.shape[0], aa_dist.shape[1]]))\n",
    "        aa_dict[pdbid] = aa_sparse   \n",
    "        \n",
    "        # am\n",
    "        am_dist = pairwise_distances(anchor_coords, masif_coords)\n",
    "        sele = np.where(am_dist<=6)\n",
    "        i = torch.LongTensor(np.vstack(sele))\n",
    "        v = torch.FloatTensor(am_dist[sele])\n",
    "        am_sparse = torch.sparse.FloatTensor(i, v, torch.Size([am_dist.shape[0], am_dist.shape[1]]))\n",
    "        am_dict[pdbid] = am_sparse\n",
    "        \n",
    "        # at\n",
    "        at_dist = pairwise_distances(anchor_coords, atom_coords)\n",
    "        sele = np.where(at_dist<=6)\n",
    "        i = torch.LongTensor(np.vstack(sele))\n",
    "        v = torch.FloatTensor(at_dist[sele])\n",
    "        at_sparse = torch.sparse.FloatTensor(i, v, torch.Size([at_dist.shape[0], at_dist.shape[1]]))\n",
    "        at_dict[pdbid] = at_sparse\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(len(am_dict), len(aa_dict), len(at_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir+'am_dict', 'wb') as f:\n",
    "    pickle.dump(am_dict, f)\n",
    "with open(outdir+'aa_dict', 'wb') as f:\n",
    "    pickle.dump(aa_dict, f)\n",
    "with open(outdir+'at_dict', 'wb') as f:\n",
    "    pickle.dump(at_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymol\n",
    "import numpy as np\n",
    "\n",
    "# def get_ligand_counts_coords(filename, chains, ligand_list, removeHs=True):\n",
    "#     \"\"\"\n",
    "#     Input: \n",
    "#     filename：path+name of pdb file\n",
    "#     ligand_list: list of ligand codes (3-letter IDs)\n",
    "#     removeHs: whether to removeHs from the coordinates\n",
    "\n",
    "#     Output:\n",
    "#     count_dict: key: ligand id, value: number of occurrence\n",
    "#     coord_dict: key: ligand id + chain + residue id, value: n*3 numpy array of compound coordinates\n",
    "#     \"\"\"\n",
    "#     pymol.cmd.reinitialize()\n",
    "#     pymol.cmd.load(filename)\n",
    "#     if removeHs:\n",
    "#         pymol.cmd.remove('hydro')\n",
    "    \n",
    "#     protein_coords = []\n",
    "#     pymol.cmd.iterate_state(-1, \"chain \"+\"+\".join([x for x in chains])+\" and not het\", \"protein_coords.append((x,y,z))\", space=locals())\n",
    "\n",
    "#     count_dict, coord_dict = {}, {}\n",
    "#     list_tabu = [\"HOH\", \"DOD\", \"WAT\", \"NAG\", \"MAN\", \"UNK\", \"GLC\", \"ABA\", \"MPD\", \"GOL\", \"SO4\", \"PO4\", '', 'U', 'HEM', 'PI']\n",
    "#     list_tabu += ['ASN', \"GLY\", \"ALA\", \"PRO\", \"VAL\", \"LEU\", \"ILE\", \"MET\", \"PHE\", \"TYR\", \"TRP\", \"SER\", \"THR\", \"CYS\", \\\n",
    "#                  \"GLN\", \"LYS\", \"HIS\", \"ARG\", \"ASP\", \"GLU\"]\n",
    "#     list_ligand_ok = set()\n",
    "#     for ligand in ligand_list:\n",
    "#         if ligand in list_tabu:\n",
    "#             continue\n",
    "#         resi_set = set()\n",
    "#         ligand = ligand.upper()\n",
    "#         pymol.cmd.iterate('resname {}'.format(ligand), \"resi_set.add(chain+'_'+resi)\", space=locals())\n",
    "#         count_dict[ligand] = 0\n",
    "#         for chain_resi in resi_set:\n",
    "#             chain, resi = chain_resi.split('_')\n",
    "#             pymol.cmd.select('{}_{}'.format(ligand, chain_resi), 'chain {} and resi {}'.format(chain, resi))\n",
    "#             coords = []\n",
    "#             pymol.cmd.iterate_state(-1, '{}_{}'.format(ligand, chain_resi), \"coords.append((x,y,z))\", space=locals())\n",
    "#             if len(coords) < 5:\n",
    "#                 continue\n",
    "#             coords = np.array(coords) \n",
    "#             if pairwise_distances(protein_coords, coords).min() < 1.5:\n",
    "#                 continue\n",
    "#             if pairwise_distances(protein_coords, coords).min() > 4:\n",
    "#                 continue\n",
    "#             if pairwise_distances(protein_coords, np.mean(coords, 0, keepdims=True)).min() > 5.5:\n",
    "#                 continue\n",
    "#             coord_dict['{}_{}'.format(ligand, chain_resi)] = coords\n",
    "#             count_dict[ligand] += 1\n",
    "#             list_ligand_ok.add(ligand)\n",
    "#     return count_dict, coord_dict, list(list_ligand_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_ligand_coords = {}\n",
    "# dict_num_lig = {}\n",
    "# for i in table.index:\n",
    "#     pdbid = table.loc[i, 'pdbid']\n",
    "#     if pdbid in dict_new_name:\n",
    "#         newid = dict_new_name[pdbid]\n",
    "#     else:\n",
    "#         newid = pdbid\n",
    "#     chains = table.loc[i, 'chains']\n",
    "#     if isinstance(table.loc[i, 'ligand'], str) and len(table.loc[i, 'ligand']) > 0:\n",
    "#         list_ligand = table.loc[i, 'ligand'].split(',')\n",
    "#     else:\n",
    "#         list_ligand = []\n",
    "#     if os.path.exists('MasifOutput/00-raw_pdbs/fixed_{}.pdb'.format(newid)):\n",
    "#         filename = 'MasifOutput/00-raw_pdbs/fixed_{}.pdb'.format(newid)\n",
    "#     elif os.path.exists('MasifOutput/00-raw_pdbs/{}.pdb'.format(newid)):\n",
    "#         filename = 'MasifOutput/00-raw_pdbs/{}.pdb'.format(newid)\n",
    "#     else:\n",
    "#         print(\"NO pdb file\", pdbid)\n",
    "#         continue\n",
    "#     count_dict, coord_dict, list_ligand = get_ligand_counts_coords(filename, chains, list_ligand)\n",
    "#     dict_ligand_coords[pdbid] = coord_dict\n",
    "\n",
    "#     if len(list_ligand) == 0:\n",
    "#         table.loc[i, 'ligand_used'] = \"\"\n",
    "#     else:\n",
    "#         table.loc[i, 'ligand_used'] = \",\".join(list_ligand)\n",
    "#     dict_num_lig[pdbid] = sum(count_dict.values())\n",
    "#     table.loc[i, 'num_ligands'] = int(sum(count_dict.values()))\n",
    "#     print(i, '\\r', end=\"\")\n",
    "# table['num_ligands'] = np.array(table['num_ligands'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ligand coordinates before and after align\n",
    "def get_coord_lists(query_pdbid, chains, num_coords=None, debug=False):\n",
    "    # coords after align\n",
    "    pymol.cmd.reinitialize()\n",
    "    # pymol.cmd.remove('het')\n",
    "    pymol.cmd.load('/data/lishuya/lab/PocketAnchor/Revise1_new_data/HOLO4k_aligned/{}.pdb'.format(query_pdbid))\n",
    "    pos_after_dict = {}\n",
    "    resi_record_a = []\n",
    "    pymol.cmd.iterate('name CA and chain {}'.format(chains[0]), \n",
    "                      'resi_record_a.append(resi)', space=locals())\n",
    "    for resi in resi_record_a:\n",
    "        tmp=[]\n",
    "        pymol.cmd.iterate_state(-1, 'name CA and chain {} and resi {}'.format(chains[0], resi), \n",
    "                          'tmp.append([x,y,z])', space=locals())\n",
    "        # assert len(tmp) > 0, resi\n",
    "        pos_after_dict[resi] = tmp[0]\n",
    "    \n",
    "    # coords before align (masif processed and add h)\n",
    "    pymol.cmd.reinitialize()\n",
    "    prefix = '/data/lishuya/lab/PocketAnchorData/MasifOutput/01-benchmark_pdbs/'\n",
    "    pymol.cmd.load(prefix+'{}_{}.pdb'.format(query_pdbid, chains))\n",
    "    pos_before_dict = {}\n",
    "    resi_record_b = []\n",
    "    pymol.cmd.iterate('name CA and chain {}'.format(chains[0]), \n",
    "                      'resi_record_b.append(resi)', space=locals())\n",
    "    for resi in resi_record_b:\n",
    "        tmp = []\n",
    "        pymol.cmd.iterate_state(-1, 'name CA and chain {} and resi {}'.format(chains[0], resi), \n",
    "                          'tmp.append([x,y,z])', space=locals())\n",
    "        pos_before_dict[resi] = tmp[0]\n",
    "    resi_record = list(set(resi_record_b).intersection(resi_record_a))\n",
    "    pos_before = np.array([pos_before_dict[r] for r in resi_record])\n",
    "    pos_after = np.array([pos_after_dict[r] for r in resi_record])\n",
    "    \n",
    "    if debug:\n",
    "        print('pos_before', pos_before.shape)\n",
    "        print('resi_record', resi_record, len(resi_record))\n",
    "        print('pos_after', pos_after.shape)\n",
    "    assert len(pos_before) == len(pos_after)\n",
    "    if num_coords is not None:\n",
    "        pos_before = pos_before[:num_coords]\n",
    "        pos_after = pos_after[:num_coords]\n",
    "        if debug:\n",
    "            print('pos_before', pos_before.shape)\n",
    "            print('pos_after', pos_after.shape)\n",
    "    return pos_before, pos_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_position(Xref, Yref, X):\n",
    "    c1 = Xref.mean(1, keepdims=True)\n",
    "    c2 = Yref.mean(1, keepdims=True)\n",
    "    H = np.matmul((Xref - c1), (Yref - c2).T)\n",
    "    U, D, V = np.linalg.svd(H)\n",
    "    d = np.sign(np.linalg.det(H))\n",
    "    I = np.eye(3)\n",
    "    I[2, 2] = d\n",
    "    rotation_ = np.matmul(V.T, np.matmul(I, U.T))\n",
    "    translation_ = c2 - np.matmul(rotation_, c1)\n",
    "    Zref = np.matmul(np.linalg.inv(rotation_), Yref - translation_)\n",
    "    err = Zref - Xref\n",
    "    assert np.mean(np.abs(err))<1e-3\n",
    "    return np.matmul(rotation_, X) + translation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(dict_ligand_coords, open(outdir+\"ligand_coords_dict\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4009"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(outdir+\"ligand_coords_dict\", \"rb\") as f: # copy from PocketDetectionData_HOLO4k_da6\n",
    "    dict_ligand_coords = pickle.load(f)\n",
    "len(dict_ligand_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in table.index:\n",
    "#     ref_pdbid = table.loc[i, 'original_sample']\n",
    "#     break\n",
    "\n",
    "# dict_ligand_coords[ref_pdbid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error: failed to open file \"/data/lishuya/lab/PocketAnchorData/MasifOutput/01-benchmark_pdbs/1ksv_A.pdb\"\n",
      "453  \n",
      "490  \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### save label\n",
    "label_dict = {}\n",
    "processed = 0\n",
    "for i in table.index:\n",
    "    print(i, \" \\r\", end='')\n",
    "    query_pdbid, chains, ref_pdbid = table.loc[i, ['pdbid', 'chains', 'original_sample']]\n",
    "#     if query_pdbid in label_dict:\n",
    "#         continue\n",
    "    try:\n",
    "        anchor_coords = anchor_dict[query_pdbid]\n",
    "        cpd_coords_ref = np.concatenate(list(dict_ligand_coords[ref_pdbid].values()))\n",
    "        ca_before, ca_after = get_coord_lists(query_pdbid, chains, 100)\n",
    "        cpd_coords_query = restore_position(ca_after.T, ca_before.T, cpd_coords_ref.T).T\n",
    "        ag = pairwise_distances(anchor_coords, cpd_coords_query).min(axis=1)\n",
    "        label = (ag <= 4).astype(int)\n",
    "        label_dict[query_pdbid] = label\n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "        continue\n",
    "    \n",
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdir+'anchor_label_n4_dict_'+str(da), 'wb') as f:\n",
    "    pickle.dump(label_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 14\n",
      "922 22\n",
      "675 36\n",
      "350 6\n",
      "594 6\n",
      "327 7\n",
      "324 8\n",
      "335 7\n",
      "674 30\n",
      "638 13\n",
      "311 20\n",
      "725 19\n",
      "425 3\n",
      "467 0\n",
      "538 0\n",
      "487 14\n",
      "379 8\n",
      "599 0\n",
      "440 0\n",
      "360 0\n",
      "390 11\n",
      "397 9\n",
      "624 7\n",
      "336 0\n",
      "343 0\n",
      "349 0\n",
      "1010 12\n",
      "1167 7\n",
      "359 18\n",
      "744 11\n",
      "533 10\n",
      "556 6\n",
      "565 0\n",
      "344 4\n",
      "356 3\n",
      "341 5\n",
      "1329 12\n",
      "530 7\n",
      "996 13\n",
      "366 12\n",
      "326 13\n",
      "331 11\n",
      "991 15\n",
      "645 11\n",
      "440 6\n",
      "429 6\n",
      "440 7\n",
      "448 6\n",
      "428 8\n",
      "441 8\n",
      "375 9\n",
      "1484 12\n",
      "455 12\n",
      "413 16\n",
      "325 5\n",
      "337 0\n",
      "335 15\n",
      "337 15\n",
      "208 19\n",
      "335 1\n",
      "546 0\n",
      "198 2\n",
      "411 0\n",
      "527 11\n",
      "766 0\n",
      "343 0\n",
      "255 0\n",
      "382 0\n",
      "335 0\n",
      "310 4\n",
      "514 9\n",
      "508 0\n",
      "487 0\n",
      "505 10\n",
      "495 0\n",
      "292 0\n",
      "670 0\n",
      "665 0\n",
      "570 0\n",
      "424 0\n",
      "524 20\n",
      "789 0\n",
      "697 0\n",
      "1036 0\n",
      "1422 11\n",
      "590 0\n",
      "774 0\n",
      "399 13\n",
      "1056 14\n",
      "1101 6\n",
      "596 19\n",
      "277 0\n",
      "1113 0\n",
      "2244 0\n",
      "552 8\n",
      "542 25\n",
      "535 22\n",
      "542 0\n",
      "361 3\n",
      "557 0\n",
      "649 13\n",
      "1945 8\n",
      "544 17\n",
      "326 16\n",
      "1433 9\n",
      "294 14\n",
      "1045 22\n",
      "910 11\n",
      "366 16\n",
      "534 14\n",
      "762 0\n",
      "512 7\n",
      "496 7\n",
      "616 0\n",
      "515 0\n",
      "985 0\n",
      "1469 0\n",
      "1460 0\n",
      "1405 21\n",
      "572 13\n",
      "386 3\n",
      "368 0\n",
      "746 0\n",
      "508 0\n",
      "381 0\n",
      "403 0\n",
      "479 7\n",
      "501 11\n",
      "343 0\n",
      "271 16\n",
      "643 21\n",
      "487 11\n",
      "488 13\n",
      "393 0\n",
      "434 0\n",
      "430 1\n",
      "810 0\n",
      "954 0\n",
      "480 0\n",
      "458 0\n",
      "775 0\n",
      "387 0\n",
      "341 16\n",
      "458 0\n",
      "759 21\n",
      "536 20\n",
      "525 0\n",
      "496 20\n",
      "1041 0\n",
      "453 9\n",
      "412 6\n",
      "1100 0\n",
      "1575 15\n",
      "589 16\n",
      "506 0\n",
      "1076 19\n",
      "337 6\n",
      "1039 10\n",
      "849 13\n",
      "661 0\n",
      "515 0\n",
      "187 0\n",
      "714 8\n",
      "566 16\n",
      "688 5\n",
      "669 6\n",
      "396 1\n",
      "630 14\n",
      "312 20\n",
      "358 0\n",
      "530 0\n",
      "482 12\n",
      "1495 18\n",
      "999 6\n",
      "267 0\n",
      "1084 14\n",
      "497 0\n",
      "531 0\n",
      "844 4\n",
      "1411 11\n",
      "719 0\n",
      "821 3\n",
      "765 4\n",
      "745 6\n",
      "661 5\n",
      "959 0\n",
      "750 15\n",
      "257 7\n",
      "504 0\n",
      "368 7\n",
      "441 0\n",
      "399 0\n",
      "448 12\n",
      "662 0\n",
      "393 8\n",
      "759 0\n",
      "778 0\n",
      "282 0\n",
      "545 0\n",
      "745 0\n",
      "494 0\n",
      "755 17\n",
      "330 0\n",
      "329 0\n",
      "314 18\n",
      "437 0\n",
      "1911 0\n",
      "774 0\n",
      "750 0\n",
      "684 0\n",
      "1405 0\n",
      "339 0\n",
      "255 16\n",
      "252 22\n",
      "453 0\n",
      "826 0\n",
      "878 0\n",
      "769 0\n",
      "1473 5\n",
      "384 8\n",
      "364 4\n",
      "287 0\n",
      "438 7\n",
      "921 0\n",
      "869 0\n",
      "346 0\n",
      "875 0\n",
      "880 1\n",
      "416 6\n",
      "546 8\n",
      "377 0\n",
      "332 0\n",
      "964 7\n",
      "1019 0\n",
      "357 0\n",
      "771 0\n",
      "800 0\n",
      "456 0\n",
      "443 0\n",
      "529 13\n",
      "253 15\n",
      "797 0\n",
      "1153 0\n",
      "431 0\n",
      "416 4\n",
      "419 5\n",
      "542 0\n",
      "1528 17\n",
      "846 4\n",
      "982 0\n",
      "350 0\n",
      "384 0\n",
      "645 0\n",
      "709 28\n",
      "745 18\n",
      "520 0\n",
      "666 1\n",
      "603 17\n",
      "643 22\n",
      "780 30\n",
      "1505 6\n",
      "537 15\n",
      "537 17\n",
      "595 0\n",
      "606 9\n",
      "763 0\n",
      "1574 15\n",
      "1354 10\n",
      "1496 3\n",
      "1467 3\n",
      "762 0\n",
      "400 5\n",
      "1001 0\n",
      "198 1\n",
      "374 6\n",
      "387 15\n",
      "753 12\n",
      "379 9\n",
      "746 0\n",
      "782 0\n",
      "419 5\n",
      "410 7\n",
      "815 0\n",
      "402 4\n",
      "401 5\n",
      "2251 12\n",
      "1791 0\n",
      "318 0\n",
      "621 2\n",
      "328 0\n",
      "337 0\n",
      "340 0\n",
      "396 0\n",
      "331 9\n",
      "806 0\n",
      "1020 5\n",
      "934 0\n",
      "369 0\n",
      "214 10\n",
      "495 1\n",
      "1342 0\n",
      "275 0\n",
      "628 17\n",
      "770 11\n",
      "455 0\n",
      "1051 0\n",
      "408 0\n",
      "1966 0\n",
      "765 15\n",
      "733 10\n",
      "380 16\n",
      "514 7\n",
      "623 17\n",
      "547 5\n",
      "531 3\n",
      "332 6\n",
      "329 6\n",
      "334 7\n",
      "257 0\n",
      "262 0\n",
      "259 0\n",
      "248 4\n",
      "483 0\n",
      "418 3\n",
      "256 0\n",
      "369 0\n",
      "337 18\n",
      "754 11\n",
      "1307 0\n",
      "396 23\n",
      "528 0\n",
      "548 0\n",
      "1141 0\n",
      "392 6\n",
      "264 19\n",
      "721 10\n",
      "738 6\n",
      "584 1\n",
      "769 25\n",
      "496 9\n",
      "330 14\n",
      "372 11\n",
      "533 27\n",
      "259 0\n",
      "559 13\n",
      "502 13\n",
      "435 0\n",
      "404 11\n",
      "540 0\n",
      "536 0\n",
      "834 4\n",
      "459 12\n",
      "348 4\n",
      "923 16\n",
      "284 1\n",
      "723 23\n",
      "1349 6\n",
      "793 1\n",
      "268 24\n",
      "278 0\n",
      "729 25\n",
      "734 0\n",
      "316 7\n",
      "494 1\n",
      "493 3\n",
      "678 15\n",
      "463 6\n",
      "316 23\n",
      "1297 0\n",
      "452 4\n",
      "387 15\n",
      "408 6\n",
      "430 8\n",
      "724 6\n",
      "299 12\n",
      "1042 11\n",
      "488 0\n",
      "238 0\n",
      "411 18\n",
      "1184 6\n",
      "393 0\n",
      "453 14\n",
      "615 1\n",
      "641 1\n",
      "664 18\n",
      "634 17\n",
      "1118 0\n",
      "461 14\n",
      "483 0\n",
      "507 0\n",
      "977 5\n",
      "599 0\n",
      "642 10\n",
      "594 20\n",
      "641 19\n",
      "349 22\n",
      "1048 0\n",
      "364 0\n",
      "1094 0\n",
      "785 0\n",
      "263 10\n",
      "273 0\n",
      "272 8\n",
      "269 10\n",
      "1444 2\n",
      "401 5\n",
      "376 7\n",
      "385 8\n",
      "404 7\n",
      "396 16\n",
      "759 22\n",
      "793 12\n",
      "717 1\n",
      "722 16\n",
      "751 28\n",
      "728 25\n",
      "384 0\n",
      "397 10\n",
      "788 0\n",
      "768 19\n",
      "774 13\n",
      "780 19\n",
      "363 0\n",
      "367 24\n",
      "1021 0\n",
      "1041 0\n",
      "1038 0\n",
      "591 0\n",
      "1140 0\n",
      "663 0\n",
      "774 0\n",
      "413 5\n",
      "510 0\n",
      "390 0\n",
      "783 0\n",
      "742 0\n",
      "750 0\n",
      "757 0\n",
      "758 0\n",
      "1837 0\n",
      "1373 0\n",
      "1047 0\n",
      "332 0\n",
      "321 0\n",
      "324 0\n",
      "746 21\n",
      "415 0\n",
      "322 6\n",
      "317 4\n",
      "724 2\n",
      "774 0\n",
      "300 12\n",
      "317 0\n",
      "422 13\n",
      "1027 27\n",
      "852 3\n",
      "376 9\n",
      "414 6\n",
      "399 6\n",
      "204 4\n",
      "209 5\n",
      "227 5\n",
      "1768 0\n",
      "968 8\n",
      "252 0\n",
      "258 0\n",
      "389 1\n",
      "1819 0\n",
      "316 22\n",
      "637 10\n",
      "480 16\n",
      "162 15\n",
      "269 11\n",
      "381 11\n",
      "484 13\n",
      "615 9\n",
      "392 0\n",
      "427 6\n",
      "261 9\n",
      "260 0\n",
      "360 11\n",
      "404 12\n",
      "273 26\n",
      "305 18\n",
      "2030 6\n",
      "509 0\n",
      "717 6\n",
      "526 0\n",
      "626 11\n"
     ]
    }
   ],
   "source": [
    "for value in label_dict.values():\n",
    "    print(value.size, value.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save final dataset table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  \r",
      "1  \r",
      "2  \r",
      "3  \r",
      "4  \r",
      "5  \r",
      "6  \r",
      "7  \r",
      "8  \r",
      "9  \r",
      "10  \r",
      "11  \r",
      "12  \r",
      "13  \r",
      "14  \r",
      "15  \r",
      "16  \r",
      "17  \r",
      "18  \r",
      "19  \r",
      "20  \r",
      "21  \r",
      "22  \r",
      "23  \r",
      "24  \r",
      "25  \r",
      "26  \r",
      "27  \r",
      "28  \r",
      "29  \r",
      "30  \r",
      "31  \r",
      "32  \r",
      "33  \r",
      "34  \r",
      "35  \r",
      "36  \r",
      "37  \r",
      "38  \r",
      "39  \r",
      "40  \r",
      "41  \r",
      "42  \r",
      "43  \r",
      "44  \r",
      "45  \r",
      "46  \r",
      "47  \r",
      "48  \r",
      "49  \r",
      "50  \r",
      "51  \r",
      "52  \r",
      "53  \r",
      "54  \r",
      "55  \r",
      "56  \r",
      "57  \r",
      "58  \r",
      "59  \r",
      "60  \r",
      "61  \r",
      "62  \r",
      "63  \r",
      "64  \r",
      "65  \r",
      "66  \r",
      "67  \r",
      "68  \r",
      "69  \r",
      "70  \r",
      "71  \r",
      "72  \r",
      "73  \r",
      "74  \r",
      "75  \r",
      "76  \r",
      "77  \r",
      "78  \r",
      "79  \r",
      "80  \r",
      "81  \r",
      "82  \r",
      "83  \r",
      "84  \r",
      "85  \r",
      "86  \r",
      "87  \r",
      "88  \r",
      "89  \r",
      "90  \r",
      "91  \r",
      "92  \r",
      "93  \r",
      "94  \r",
      "95  \r",
      "96  \r",
      "97  \r",
      "98  \r",
      "99  \r",
      "100  \r",
      "101  \r",
      "102  \r",
      "103  \r",
      "104  \r",
      "105  \r",
      "106  \r",
      "107  \r",
      "108  \r",
      "109  \r",
      "110  \r",
      "111  \r",
      "112  \r",
      "113  \r",
      "114  \r",
      "115  \r",
      "116  \r",
      "117  \r",
      "118  \r",
      "119  \r",
      "120  \r",
      "121  \r",
      "122  \r",
      "123  \r",
      "124  \r",
      "125  \r",
      "126  \r",
      "127  \r",
      "128  \r",
      "129  \r",
      "130  \r",
      "131  \r",
      "132  \r",
      "133  \r",
      "134  \r",
      "135  \r",
      "136  \r",
      "137  \r",
      "138  \r",
      "139  \r",
      "140  \r",
      "141  \r",
      "142  \r",
      "143  \r",
      "144  \r",
      "145  \r",
      "146  \r",
      "147  \r",
      "148  \r",
      "149  \r",
      "150  \r",
      "151  \r",
      "152  \r",
      "153  \r",
      "154  \r",
      "155  \r",
      "156  \r",
      "157  \r",
      "158  \r",
      "159  \r",
      "160  \r",
      "161  \r",
      "162  \r",
      "163  \r",
      "164  \r",
      "165  \r",
      "166  \r",
      "167  \r",
      "168  \r",
      "169  \r",
      "170  \r",
      "171  \r",
      "172  \r",
      "173  \r",
      "174  \r",
      "175  \r",
      "176  \r",
      "177  \r",
      "178  \r",
      "179  \r",
      "180  \r",
      "181  \r",
      "182  \r",
      "183  \r",
      "184  \r",
      "185  \r",
      "186  \r",
      "187  \r",
      "188  \r",
      "189  \r",
      "190  \r",
      "191  \r",
      "192  \r",
      "193  \r",
      "194  \r",
      "195  \r",
      "196  \r",
      "197  \r",
      "198  \r",
      "199  \r",
      "200  \r",
      "201  \r",
      "202  \r",
      "203  \r",
      "204  \r",
      "205  \r",
      "206  \r",
      "207  \r",
      "208  \r",
      "209  \r",
      "210  \r",
      "211  \r",
      "212  \r",
      "213  \r",
      "214  \r",
      "215  \r",
      "216  \r",
      "217  \r",
      "218  \r",
      "219  \r",
      "220  \r",
      "221  \r",
      "222  \r",
      "223  \r",
      "224  \r",
      "225  \r",
      "226  \r",
      "227  \r",
      "228  \r",
      "229  \r",
      "230  \r",
      "231  \r",
      "232  \r",
      "233  \r",
      "234  \r",
      "235  \r",
      "236  \r",
      "237  \r",
      "238  \r",
      "239  \r",
      "240  \r",
      "241  \r",
      "242  \r",
      "243  \r",
      "244  \r",
      "245  \r",
      "246  \r",
      "247  \r",
      "248  \r",
      "249  \r",
      "250  \r",
      "251  \r",
      "252  \r",
      "253  \r",
      "254  \r",
      "255  \r",
      "256  \r",
      "257  \r",
      "258  \r",
      "259  \r",
      "260  \r",
      "261  \r",
      "262  \r",
      "263  \r",
      "264  \r",
      "265  \r",
      "266  \r",
      "267  \r",
      "268  \r",
      "269  \r",
      "270  \r",
      "271  \r",
      "272  \r",
      "273  \r",
      "274  \r",
      "275  \r",
      "276  \r",
      "277  \r",
      "278  \r",
      "279  \r",
      "280  \r",
      "281  \r",
      "282  \r",
      "283  \r",
      "284  \r",
      "285  \r",
      "286  \r",
      "287  \r",
      "288  \r",
      "289  \r",
      "290  \r",
      "291  \r",
      "292  \r",
      "293  \r",
      "294  \r",
      "295  \r",
      "296  \r",
      "297  \r",
      "298  \r",
      "299  \r",
      "300  \r",
      "301  \r",
      "302  \r",
      "303  \r",
      "304  \r",
      "305  \r",
      "306  \r",
      "307  \r",
      "308  \r",
      "309  \r",
      "310  \r",
      "311  \r",
      "312  \r",
      "313  \r",
      "314  \r",
      "315  \r",
      "316  \r",
      "317  \r",
      "318  \r",
      "319  \r",
      "320  \r",
      "321  \r",
      "322  \r",
      "323  \r",
      "324  \r",
      "325  \r",
      "326  \r",
      "327  \r",
      "328  \r",
      "329  \r",
      "330  \r",
      "331  \r",
      "332  \r",
      "333  \r",
      "334  \r",
      "335  \r",
      "336  \r",
      "337  \r",
      "338  \r",
      "339  \r",
      "340  \r",
      "341  \r",
      "342  \r",
      "343  \r",
      "344  \r",
      "345  \r",
      "346  \r",
      "347  \r",
      "348  \r",
      "349  \r",
      "350  \r",
      "351  \r",
      "352  \r",
      "353  \r",
      "354  \r",
      "355  \r",
      "356  \r",
      "357  \r",
      "358  \r",
      "359  \r",
      "360  \r",
      "361  \r",
      "362  \r",
      "363  \r",
      "364  \r",
      "365  \r",
      "366  \r",
      "367  \r",
      "368  \r",
      "369  \r",
      "370  \r",
      "371  \r",
      "372  \r",
      "373  \r",
      "374  \r",
      "375  \r",
      "376  \r",
      "377  \r",
      "378  \r",
      "379  \r",
      "380  \r",
      "381  \r",
      "382  \r",
      "383  \r",
      "384  \r",
      "385  \r",
      "386  \r",
      "387  \r",
      "388  \r",
      "389  \r",
      "390  \r",
      "391  \r",
      "392  \r",
      "393  \r",
      "394  \r",
      "395  \r",
      "396  \r",
      "397  \r",
      "398  \r",
      "399  \r",
      "400  \r",
      "401  \r",
      "402  \r",
      "403  \r",
      "404  \r",
      "405  \r",
      "406  \r",
      "407  \r",
      "408  \r",
      "409  \r",
      "410  \r",
      "411  \r",
      "412  \r",
      "413  \r",
      "414  \r",
      "415  \r",
      "416  \r",
      "417  \r",
      "418  \r",
      "419  \r",
      "420  \r",
      "421  \r",
      "422  \r",
      "423  \r",
      "424  \r",
      "425  \r",
      "426  \r",
      "427  \r",
      "428  \r",
      "429  \r",
      "430  \r",
      "431  \r",
      "432  \r",
      "433  \r",
      "434  \r",
      "435  \r",
      "436  \r",
      "437  \r",
      "438  \r",
      "439  \r",
      "440  \r",
      "441  \r",
      "442  \r",
      "443  \r",
      "444  \r",
      "445  \r",
      "446  \r",
      "447  \r",
      "448  \r",
      "449  \r",
      "450  \r",
      "451  \r",
      "452  \r",
      "453  \r",
      "454  \r",
      "455  \r",
      "456  \r",
      "457  \r",
      "458  \r",
      "459  \r",
      "460  \r",
      "461  \r",
      "462  \r",
      "463  \r",
      "464  \r",
      "465  \r",
      "466  \r",
      "467  \r",
      "468  \r",
      "469  \r",
      "470  \r",
      "471  \r",
      "472  \r",
      "473  \r",
      "474  \r",
      "475  \r",
      "476  \r",
      "477  \r",
      "478  \r",
      "479  \r",
      "480  \r",
      "481  \r",
      "482  \r",
      "483  \r",
      "484  \r",
      "485  \r",
      "486  \r",
      "487  \r",
      "488  \r",
      "489  \r",
      "490  \r",
      "success_list 489\n"
     ]
    }
   ],
   "source": [
    "success_list = []\n",
    "for i in table.index:\n",
    "    print(i, \" \\r\", end='')\n",
    "    pdbid = table.loc[i, 'pdbid']\n",
    "    if pdbid not in anchor_dict:\n",
    "        continue\n",
    "    if pdbid not in atom_dict:\n",
    "        continue  \n",
    "    if pdbid not in masif_feature_coord_nei_dict:\n",
    "        continue  \n",
    "    if pdbid not in am_dict:\n",
    "        continue  \n",
    "    if pdbid not in at_dict:\n",
    "        continue  \n",
    "    if pdbid not in aa_dict:\n",
    "        continue  \n",
    "#     if table.loc[i, 'num_ligands'] == 0:\n",
    "#         continue\n",
    "    if pdbid not in label_dict:\n",
    "        continue  \n",
    "    \n",
    "    success_list.append(i)\n",
    "print(\"success_list\", len(success_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491\n",
      "489\n"
     ]
    }
   ],
   "source": [
    "print(table.shape[0])\n",
    "table = table.loc[success_list]\n",
    "print(table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(outdir+\"holoplus_table_pocket_full.tsv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
