{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 For reproducing results in PocketAnchor Paper or processing cutomized datasets with predefined PDB IDs and chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Prepare or load the list file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 For reproducing the results in PocketAnchor paper, please just use the lists in ./lists/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo data\n",
    "with open('lists/pdbid_chain_list_HOLO4k.txt') as f:\n",
    "    list_task = [line.strip() for line in f.readlines()]\n",
    "# print(list_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reproducing results on COACH420, please use lists/pdbid_chain_list_COACH420.txt\n",
    "\n",
    "For reproducing results on HOLO4k, please use lists/pdbid_chain_list_HOLO4k.txt\n",
    "\n",
    "For reproducing results on PDBbind, please use lists/pdbid_chain_center_list_PDBbind.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 For customized datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "customized_list = ['121p_A', '12as_AB', '13pk_ABCD', '16pk_A', '17gs_AB', '182l_A', '183l_A', '185l_A', '186l_A', '187l_A', '18gs_AB', '19gs_AB', '1a05_AB', '1a0f_AB', '1a0g_AB']\n",
    "name = 'customized_list'\n",
    "# write the list file\n",
    "with open('lists/{}.txt'.format(name), 'w') as f:\n",
    "    for item in customized_list:\n",
    "        f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['121p_A', '12as_AB', '13pk_ABCD', '16pk_A', '17gs_AB', '182l_A', '183l_A', '185l_A', '186l_A', '187l_A', '18gs_AB', '19gs_AB', '1a05_AB', '1a0f_AB', '1a0g_AB']\n"
     ]
    }
   ],
   "source": [
    "# define list_task\n",
    "with open('lists/{}.txt'.format(name)) as f:\n",
    "    list_task = [line.strip() for line in f.readlines()]\n",
    "print(list_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Download pdb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymol\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_one(pdbid):\n",
    "    if not os.path.exists('MasifOutput/download/{}.pdb'.format(pdbid)):\n",
    "        os.system('wget -P MasifOutput/download/ https://files.rcsb.org/download/{}.pdb'.format(pdbid))\n",
    "\n",
    "###############################################\n",
    "### please define this number according to \n",
    "### your computational resources\n",
    "num_processes = 32\n",
    "###############################################\n",
    "\n",
    "pdbid_list = [item[:4] for item in list_task]\n",
    "\n",
    "with Pool(num_processes) as p:\n",
    "    res = p.map(download_one, pdbid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Add hydrogens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdb(pdbid):\n",
    "    rewrite=True\n",
    "    if not os.path.exists('MasifOutput/download/{}.pdb'.format(pdbid)):\n",
    "        return\n",
    "    pymol.cmd.reinitialize()\n",
    "    pymol.cmd.load('MasifOutput/download/{}.pdb'.format(pdbid))\n",
    "    pymol.cmd.h_add(pdbid)\n",
    "    pymol.cmd.save('MasifOutput/00-raw_pdbs/{}.pdb'.format(pdbid), state=-1)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbid_list = [item[:4] for item in list_task]\n",
    "\n",
    "with Pool(num_processes) as p:\n",
    "    res = p.map(process_pdb, pdbid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the processed files\n",
    "len(os.listdir('MasifOutput/00-raw_pdbs/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Calculated MaSIF meshes and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus\n",
    "import xmlrpc.client as rpc_client\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_str = \"http://{user}:{pwd}@{host}:{port}\".format(\n",
    "    user=quote_plus(\"anchor\"),\n",
    "    pwd=quote_plus(\"pocket\"),\n",
    "    host=\"192.168.1.233\", # change this IP to that of your masif server\n",
    "    port=\"1213\"\n",
    ")\n",
    "rpc = rpc_client.ServerProxy(link_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in list_task:\n",
    "    rpc.query(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4kkg_A'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Check progress and fix the failed samples using PDBFixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdbfixer ./MasifOutput/download/1hbq.pdb  --output ./MasifOutput/download/fixed_1hbq.pdb\n",
      "pdbfixer ./MasifOutput/download/1bgt.pdb  --output ./MasifOutput/download/fixed_1bgt.pdb\n",
      "pdbfixer ./MasifOutput/download/1epa.pdb  --output ./MasifOutput/download/fixed_1epa.pdb\n",
      "pdbfixer ./MasifOutput/download/1gmc.pdb  --output ./MasifOutput/download/fixed_1gmc.pdb\n",
      "pdbfixer ./MasifOutput/download/3zv2.pdb  --output ./MasifOutput/download/fixed_3zv2.pdb\n",
      "pdbfixer ./MasifOutput/download/1oem.pdb  --output ./MasifOutput/download/fixed_1oem.pdb\n",
      "pdbfixer ./MasifOutput/download/1pyp.pdb  --output ./MasifOutput/download/fixed_1pyp.pdb\n",
      "pdbfixer ./MasifOutput/download/1kan.pdb  --output ./MasifOutput/download/fixed_1kan.pdb\n",
      "pdbfixer ./MasifOutput/download/1h6j.pdb  --output ./MasifOutput/download/fixed_1h6j.pdb\n",
      "pdbfixer ./MasifOutput/download/3t0h.pdb  --output ./MasifOutput/download/fixed_3t0h.pdb\n",
      "pdbfixer ./MasifOutput/download/1uyl.pdb  --output ./MasifOutput/download/fixed_1uyl.pdb\n",
      "pdbfixer ./MasifOutput/download/1gsb.pdb  --output ./MasifOutput/download/fixed_1gsb.pdb\n",
      "pdbfixer ./MasifOutput/download/1qhm.pdb  --output ./MasifOutput/download/fixed_1qhm.pdb\n",
      "pdbfixer ./MasifOutput/download/1dla.pdb  --output ./MasifOutput/download/fixed_1dla.pdb\n",
      "pdbfixer ./MasifOutput/download/2pfk.pdb  --output ./MasifOutput/download/fixed_2pfk.pdb\n",
      "pdbfixer ./MasifOutput/download/2tld.pdb  --output ./MasifOutput/download/fixed_2tld.pdb\n",
      "pdbfixer ./MasifOutput/download/1gsc.pdb  --output ./MasifOutput/download/fixed_1gsc.pdb\n",
      "pdbfixer ./MasifOutput/download/1ksv.pdb  --output ./MasifOutput/download/fixed_1ksv.pdb\n",
      "pdbfixer ./MasifOutput/download/1aat.pdb  --output ./MasifOutput/download/fixed_1aat.pdb\n",
      "pdbfixer ./MasifOutput/download/2gch.pdb  --output ./MasifOutput/download/fixed_2gch.pdb\n",
      "pdbfixer ./MasifOutput/download/5cha.pdb  --output ./MasifOutput/download/fixed_5cha.pdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "470"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_done = 0\n",
    "list_task_fix = []\n",
    "for task in set(list_task):\n",
    "    if rpc.check(task) == 'Done':\n",
    "        count_done += 1\n",
    "    elif rpc.check(task) == 'Failed':\n",
    "        print('pdbfixer ./MasifOutput/download/{}.pdb  --output ./MasifOutput/download/fixed_{}.pdb'\\\n",
    "              .format(task[:4], task[:4]))\n",
    "        list_task_fix.append('fixed_'+task)\n",
    "    else:\n",
    "#         pass\n",
    "        print(task, rpc.check(task))\n",
    "count_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above commands in a terminal, to fix the samples that were not successfully processed in last step.\n",
    "\n",
    "And then calculate MaSIF precomputed features for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fixed_pdb(pdbid):\n",
    "    rewrite=True\n",
    "    if not os.path.exists('MasifOutput/download/fixed_{}.pdb'.format(pdbid)):\n",
    "        return False\n",
    "    pymol.cmd.reinitialize()\n",
    "    pymol.cmd.load('MasifOutput/download/fixed_{}.pdb'.format(pdbid))\n",
    "    pymol.cmd.h_add()\n",
    "    pymol.cmd.save('MasifOutput/00-raw_pdbs/fixed_{}.pdb'.format(pdbid), state=-1)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_1hbq_A  True\n",
      "fixed_1bgt_A  True\n",
      "fixed_1epa_AB  True\n",
      "fixed_1gmc_EFG  True\n",
      "fixed_3zv2_A  True\n",
      "fixed_1oem_X  True\n",
      "fixed_1pyp_AB  True\n",
      "fixed_1kan_AB  True\n",
      "fixed_1h6j_AB  True\n",
      "fixed_3t0h_A  True\n",
      "fixed_1uyl_A  True\n",
      "fixed_1gsb_AB  True\n",
      "fixed_1qhm_AB  True\n",
      "fixed_1dla_B  True\n",
      "fixed_2pfk_CD  True\n",
      "fixed_2tld_E  True\n",
      "fixed_1gsc_AB  True\n",
      "fixed_1ksv_A  True\n",
      "fixed_1aat_AB  True\n",
      "fixed_2gch_EFG  True\n",
      "fixed_5cha_EFG  True\n"
     ]
    }
   ],
   "source": [
    "# add hydrogens\n",
    "for task in list_task_fix:\n",
    "    print(task, ' ', end=\"\")\n",
    "    print(process_fixed_pdb(task[6:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the Masif server\n",
    "for task in list_task_fix:\n",
    "    rpc.query(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_1hbq_A \t Done\n",
      "fixed_1bgt_A \t Done\n",
      "fixed_1epa_AB \t Done\n",
      "fixed_1gmc_EFG \t Done\n",
      "fixed_3zv2_A \t Done\n",
      "fixed_1oem_X \t Done\n",
      "fixed_1pyp_AB \t Done\n",
      "fixed_1kan_AB \t Done\n",
      "fixed_1h6j_AB \t Done\n",
      "fixed_3t0h_A \t Done\n",
      "fixed_1uyl_A \t Done\n",
      "fixed_1gsb_AB \t Done\n",
      "fixed_1qhm_AB \t Doing\n",
      "fixed_1dla_B \t Done\n",
      "fixed_2pfk_CD \t Done\n",
      "fixed_2tld_E \t Done\n",
      "fixed_1gsc_AB \t Done\n",
      "fixed_1ksv_A \t Failed\n",
      "fixed_1aat_AB \t Done\n",
      "fixed_2gch_EFG \t Done\n",
      "fixed_5cha_EFG \t Done\n"
     ]
    }
   ],
   "source": [
    "# check progress\n",
    "for task in list_task_fix:\n",
    "    print(task, '\\t',  rpc.check(task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 For processing datasets without predefined chains (need ligand files; e.g., PDBbind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Download pdb files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "def download_one(pdbid):\n",
    "    if not os.path.exists('MasifOutput/00-raw_pdbs/{}.pdb'.format(pdbid)):\n",
    "        os.system('wget -P MasifOutput/00-raw_pdbs/ https://files.rcsb.org/download/{}.pdb'.format(pdbid))\n",
    "\n",
    "###############################################\n",
    "### please define this number according to \n",
    "### your computational resources\n",
    "num_processes = 4 \n",
    "###############################################\n",
    "\n",
    "pdbid_list = [item[:4] for item in list_task]\n",
    "\n",
    "with Pool(num_processes) as p:\n",
    "    res = p.map(download_one, pdbid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define chains using the following demo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymol import cmd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, sys, pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "prefix = \"../\"\n",
    "pdb_datapath = prefix + \"your_local_path\"  # for raw pdb files\n",
    "pdbbind_datapath = prefix + \"your_local_path\"  # need the ligand files provided by PDBbind or other sources\n",
    "pdbchains_path = prefix + \"your_local_path\"  # for save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biomolecule(pdb_filename):\n",
    "    dict_temp = {}\n",
    "    with open(os.path.join(pdb_filename), 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            temp = line.strip().split()\n",
    "            if temp[0] == \"REMARK\":\n",
    "                if len(temp)>1 and temp[1] == \"350\":\n",
    "                    if \"BIOMOLECULE\" in line:\n",
    "                        biomol = temp[3]\n",
    "                    elif \"APPLY THE FOLLOWING TO CHAIN\" in line:\n",
    "                        added = line.strip().replace(\" \", \"\").split(':')[1].split(',')\n",
    "                        added = [item for item in added if item != \"\"]\n",
    "                        if biomol not in dict_temp:\n",
    "                            dict_temp[biomol] = []\n",
    "                        dict_temp[biomol].extend(added)\n",
    "                    elif \"AND CHAIN\" in line:\n",
    "                        added = line.strip().replace(\" \", \"\").split(':')[1].split(',')\n",
    "                        added = [item for item in added if item != \"\"]\n",
    "                        if biomol not in dict_temp:\n",
    "                            dict_temp[biomol] = []\n",
    "                        dict_temp[biomol].extend(added)\n",
    "            if temp[0] == \"ATOM\":\n",
    "                break\n",
    "            line = f.readline()\n",
    "    return dict_temp\n",
    "\n",
    "\n",
    "def select_biomolecule(pdb_filename, chain_dict, ligand_filename):\n",
    "    distance_dict = {}\n",
    "    cmd.reinitialize()\n",
    "    cmd.load(pdb_datapath + pdbid + '.pdb')\n",
    "    cmd.load(pdbbind_datapath + pdbid + '/' + pdbid + '_ligand.sdf')\n",
    "    ligand_coords = []\n",
    "    cmd.iterate_state(-1, '{}_ligand'.format(pdbid), 'ligand_coords.append([x,y,z])', space=locals())\n",
    "        \n",
    "    for biomol, chain_list in chain_dict.items():\n",
    "        cmd.select('biomol_{}'.format(biomol), 'chain {}'.format('+'.join(chain_list)))\n",
    "        coords = []\n",
    "        cmd.iterate_state(-1, 'biomol_{}'.format(biomol), 'coords.append([x,y,z])', space=locals())\n",
    "        if len(coords) > 0:\n",
    "            dist = pairwise_distances(ligand_coords, coords)\n",
    "            distance_dict[biomol] = dist.min()\n",
    "        else:\n",
    "            distance_dict[biomol] = np.nan\n",
    "    return distance_dict\n",
    "\n",
    "def get_all_chains(pdbid):\n",
    "    cmd.reinitialize()\n",
    "    cmd.load(pdb_datapath+'{}.pdb'.format(pdbid))\n",
    "    cmd.remove('het')\n",
    "    chains = set()\n",
    "    for x in cmd.get_names():\n",
    "        # print('x', x)\n",
    "        for ch in cmd.get_chains(x):\n",
    "            chains.add(ch)\n",
    "            #print(x, \" has chain \", ch)\n",
    "    return chains\n",
    "\n",
    "def get_remove_chains(pdbid):\n",
    "    cmd.reinitialize()\n",
    "    cmd.load(pdb_datapath+'{}.pdb'.format(pdbid))\n",
    "    cmd.remove('het')\n",
    "    cmd.load(pdbbind_datapath+'{}/{}_ligand.sdf'.format(pdbid, pdbid))\n",
    "    cmd.select('near_ligand', '{}_ligand expand 0.1'.format(pdbid))\n",
    "    chains = set()\n",
    "    cmd.iterate('near_ligand', 'chains.add(chain)', space=locals())\n",
    "    if '' in chains:\n",
    "        chains = chains - {''}\n",
    "    return chains\n",
    "\n",
    "\n",
    "def get_chains_one_sample(pdbid, isprint=False, isread=True):\n",
    "    if isread:\n",
    "        if os.path.exists(pdbchains_path + pdbid):\n",
    "            with open(pdbchains_path + pdbid, 'r') as f:\n",
    "                chains = f.readline().strip()\n",
    "            return chains\n",
    "    \n",
    "    biomol_dict = get_biomolecule(pdbid)\n",
    "    if isprint:\n",
    "        print('biomol_dict', biomol_dict)\n",
    "    try:\n",
    "        result_dict = select_biomolecule(pdbid, biomol_dict)\n",
    "    except Exception as E:\n",
    "        print(pdbid, E)\n",
    "        return \"\"\n",
    "    if isprint:\n",
    "        print('result_dict', result_dict)\n",
    "    if len(biomol_dict) == 0:\n",
    "        select_chains = get_all_chains(pdbid)\n",
    "    else:\n",
    "        select_key, selected_value = '', 99999\n",
    "        for key, value in result_dict.items():\n",
    "            if value != np.nan and value < selected_value:\n",
    "                selected_value = value\n",
    "                select_key = key\n",
    "        if isprint:\n",
    "            print('select_key', select_key)\n",
    "        assert select_key != '', pdbid\n",
    "        select_chains = biomol_dict[select_key]\n",
    "    if isprint:\n",
    "        print('select_chains', select_chains)\n",
    "    remove_chains = get_remove_chains(pdbid)\n",
    "    if isprint:\n",
    "        print('remove_chains', remove_chains)\n",
    "    final_chains  = list(set(select_chains) - remove_chains)\n",
    "    if isprint:\n",
    "        print('final_chains', final_chains)\n",
    "        \n",
    "    chains = \"\".join(sorted(final_chains))\n",
    "    with open(pdbchains_path + pdbid, 'w') as f:\n",
    "        f.write(chains)\n",
    "        \n",
    "    return chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbid = '1a1e'\n",
    "get_chains_one_sample(pdbid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Then prepare the lists of [PDBID_CHAINS], and run the steps in Section 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
